{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import setGPU\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torchvision import models\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "sys.path.append(\"../../ScriptsRL\")\n",
    "from config import DATA_DIR, MANIPULATED_DATA_DIR, RAW_DATA_FOLDER\n",
    "from models import *\n",
    "\n",
    "from misc_functions import preprocess_image, recreate_image, save_image\n",
    "#from cnn_layer_visualization import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encoder_decoder_model(\n",
       "  (cnn): Sequential(\n",
       "    (0): Conv2d(5, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Sigmoid()\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Sigmoid()\n",
       "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Sigmoid()\n",
       "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): Sigmoid()\n",
       "    (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): Sigmoid()\n",
       "    (11): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): Sigmoid()\n",
       "    (13): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): Sigmoid()\n",
       "    (16): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (maxpool): MaxPool3d(kernel_size=(1, 1, 10), stride=(1, 1, 10), padding=0, dilation=1, ceil_mode=False)\n",
       "  (encoder): Sequential(\n",
       "    (0): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.8, inplace=False)\n",
       "    (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=5120, bias=True)\n",
       "  )\n",
       "  (subject_classifier): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=20, bias=True)\n",
       "    (1): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file ='new_models/expnum_all_freq_bands_20sub_120sec_20frame_5slide_1024d_lmbd00_noBN_sigm_lambda_0.0_lr_1e-05/test_subject_all_epoch_99.pth'\n",
    "model=torch.load(os.path.join(\"../../Results/{}\".format(model_file)) )\n",
    "\n",
    "for i,p in enumerate(model.parameters()):\n",
    "    p.requires_grad = False\n",
    "model=model.eval()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLayerVisualization():\n",
    "    \"\"\"\n",
    "        Produces an image that minimizes the loss of a convolution\n",
    "        operation for a specific layer and filter\n",
    "    \"\"\"\n",
    "    def __init__(self, model, selected_layer, selected_filter):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.selected_layer = selected_layer\n",
    "        self.selected_filter = selected_filter\n",
    "        self.conv_output = 0\n",
    "        # Create the folder to export images if not exists\n",
    "        if not os.path.exists('../generated'):\n",
    "            os.makedirs('../generated')\n",
    "\n",
    "    def hook_layer(self):\n",
    "        def hook_function(module, grad_in, grad_out):\n",
    "            # Gets the conv output of the selected filter (from selected layer)\n",
    "            self.conv_output = grad_out[0, self.selected_filter]\n",
    "        # Hook the selected layer\n",
    "        self.model[self.selected_layer].register_forward_hook(hook_function)\n",
    "\n",
    "    def visualise_layer_with_hooks(self):\n",
    "        # Hook the selected layer\n",
    "        self.hook_layer()\n",
    "        # Generate a random image\n",
    "        random_image = np.uint8(np.random.uniform(150, 180, (32, 32, 5)))\n",
    "        # Process image and return variable\n",
    "        #processed_image = preprocess_image(random_image, False)\n",
    "        processed_image = torch.from_numpy(random_image.transpose(2, 0, 1)).float()\n",
    "        processed_image = Variable(processed_image, requires_grad=True)\n",
    "        \n",
    "        # Define optimizer for the image\n",
    "        optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "        for i in range(1, 31):\n",
    "            optimizer.zero_grad()\n",
    "            # Assign create image to a variable to move forward in the model\n",
    "            x = processed_image\n",
    "            for index, layer in enumerate(self.model):\n",
    "                # Forward pass layer by layer\n",
    "                # x is not used after this point because it is only needed to trigger\n",
    "                # the forward hook function\n",
    "                x = layer(x)\n",
    "                # Only need to forward until the selected layer is reached\n",
    "                if index == self.selected_layer:\n",
    "                    # (forward hook function triggered)\n",
    "                    break\n",
    "            # Loss function is the mean of the output of the selected layer/filter\n",
    "            # We try to minimize the mean of the output of that specific filter\n",
    "            loss = -torch.mean(self.conv_output)\n",
    "            #print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "            \n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            # Update image\n",
    "            optimizer.step()\n",
    "            # Recreate image\n",
    "            self.created_image = recreate_image(processed_image[:,:,[0,1,4]])\n",
    "            # Save image\n",
    "            if i % 5 == 0:\n",
    "                im_path = '../generated/layer_vis_l' + str(self.selected_layer) + \\\n",
    "                    '_f' + str(self.selected_filter) + '_iter' + str(i) + '.jpg'\n",
    "                save_image(self.created_image, im_path)\n",
    "            print(f'Image created at:{im_path}')\n",
    "            \n",
    "            \n",
    "    def visualise_layer_without_hooks(self):\n",
    "        # Process image and return variable\n",
    "        # Generate a random image\n",
    "        random_image = np.uint8(np.random.uniform(150, 180, (224, 224, 5)))\n",
    "        # Process image and return variable\n",
    "        processed_image = preprocess_image(random_image, False)\n",
    "        # Define optimizer for the image\n",
    "        optimizer = Adam([processed_image], lr=0.1, weight_decay=1e-6)\n",
    "        for i in range(1, 31):\n",
    "            optimizer.zero_grad()\n",
    "            # Assign create image to a variable to move forward in the model\n",
    "            x = processed_image\n",
    "            for index, layer in enumerate(self.model):\n",
    "                # Forward pass layer by layer\n",
    "                x = layer(x)\n",
    "                if index == self.selected_layer:\n",
    "                    # Only need to forward until the selected layer is reached\n",
    "                    # Now, x is the output of the selected layer\n",
    "                    break\n",
    "            # Here, we get the specific filter from the output of the convolution operation\n",
    "            # x is a tensor of shape 1x512x28x28.(For layer 17)\n",
    "            # So there are 512 unique filter outputs\n",
    "            # Following line selects a filter from 512 filters so self.conv_output will become\n",
    "            # a tensor of shape 28x28\n",
    "            self.conv_output = x[0, self.selected_filter]\n",
    "            # Loss function is the mean of the output of the selected layer/filter\n",
    "            # We try to minimize the mean of the output of that specific filter\n",
    "            loss = -torch.mean(self.conv_output)\n",
    "            #print('Iteration:', str(i), 'Loss:', \"{0:.2f}\".format(loss.data.numpy()))\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            # Update image\n",
    "            optimizer.step()\n",
    "            # Recreate image\n",
    "            self.created_image = recreate_image(processed_image[:,:,[0,1,4]])\n",
    "            # Save image\n",
    "            if i % 5 == 0:\n",
    "                im_path = '../generated/layer_vis_l' + str(self.selected_layer) + \\\n",
    "                    '_f' + str(self.selected_filter) + '_iter' + str(i) + '.jpg'\n",
    "                save_image(self.created_image, im_path)\n",
    "            print(f'Image created at:{im_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_layer = 0\n",
    "filter_pos = 10\n",
    "# Fully connected layer is not needed\n",
    "pretrained_model = model.cnn #models.vgg16(pretrained=True).features\n",
    "layer_vis = CNNLayerVisualization(pretrained_model, cnn_layer, filter_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer visualization with pytorch hooks\n",
    "layer_vis.visualise_layer_with_hooks()\n",
    "\n",
    "# Layer visualization without pytorch hooks\n",
    "#layer_vis.visualise_layer_without_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
